{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned Data:\n",
      "       image_name comment_number  \\\n",
      "0  1000092795.jpg              0   \n",
      "1  1000092795.jpg              1   \n",
      "2  1000092795.jpg              2   \n",
      "3  1000092795.jpg              3   \n",
      "4  1000092795.jpg              4   \n",
      "\n",
      "                                             comment  \n",
      "0  Two young guys with shaggy hair look at their ...  \n",
      "1  Two young , White males are outside near many ...  \n",
      "2   Two men in green shirts are standing in a yard .  \n",
      "3       A man in a blue shirt standing in a garden .  \n",
      "4            Two friends enjoy time spent together .  \n",
      "Cleaned data saved to C:\\Users\\nputta\\Downloads\\OMVK_MS_PROJECT\\cleaned_data.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def clean_and_reorganize_data(file_path, output_file):\n",
    "    \"\"\"\n",
    "    Clean and reorganize data into a tabular format with columns:\n",
    "    'image_name', 'comment_number', 'comment'.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the input CSV file.\n",
    "        output_file (str): Path to save the cleaned CSV file.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load the raw file into memory\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            lines = f.readlines()\n",
    "\n",
    "        # Clean up lines by stripping extra spaces and quotation marks\n",
    "        cleaned_lines = []\n",
    "        for line in lines:\n",
    "            cleaned_line = line.replace('\"', '').strip()  # Remove quotation marks\n",
    "            cleaned_lines.append(cleaned_line)\n",
    "\n",
    "        # Save the cleaned content temporarily\n",
    "        temp_file = \"temp_cleaned_file.csv\"\n",
    "        with open(temp_file, 'w', encoding='utf-8') as f:\n",
    "            f.writelines(\"\\n\".join(cleaned_lines))\n",
    "\n",
    "        # Read the cleaned file with a proper delimiter\n",
    "        data = pd.read_csv(temp_file, delimiter='|', engine='python', skipinitialspace=True)\n",
    "\n",
    "        # Rename columns and strip whitespace\n",
    "        data.columns = ['image_name', 'comment_number', 'comment']\n",
    "        data['image_name'] = data['image_name'].str.strip()\n",
    "        data['comment_number'] = data['comment_number'].str.strip()\n",
    "        data['comment'] = data['comment'].str.strip()\n",
    "\n",
    "        # Debug: Print cleaned data for validation\n",
    "        print(\"Cleaned Data:\")\n",
    "        print(data.head())\n",
    "\n",
    "        # Save the cleaned data to a new CSV file\n",
    "        data.to_csv(output_file, index=False)\n",
    "        print(f\"Cleaned data saved to {output_file}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error cleaning and reorganizing data: {e}\")\n",
    "\n",
    "# Example usage\n",
    "file_path = r\"C:\\Users\\nputta\\Downloads\\OMVK_MS_PROJECT\\results.csv\"  # Path to the raw CSV file\n",
    "output_file = r\"C:\\Users\\nputta\\Downloads\\OMVK_MS_PROJECT\\cleaned_data.csv\"  # Correct file path with .csv extension\n",
    "\n",
    "clean_and_reorganize_data(file_path, output_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading the file: C:\\Users\\nputta\\Downloads\\OMVK_MS_PROJECT\\results.csv\n",
      "Cleaned Lines (First 5):\n",
      "['image_name| comment_number| comment', '1000092795.jpg| 0| Two young guys with shaggy hair look at their hands while hanging out in the yard .', '1000092795.jpg| 1| Two young , White males are outside near many bushes .', '1000092795.jpg| 2| Two men in green shirts are standing in a yard .', '1000092795.jpg| 3| A man in a blue shirt standing in a garden .']\n",
      "Reading temporary cleaned file: temp_cleaned_file.csv\n",
      "Cleaned Data (First 5 Rows):\n",
      "       image_name comment_number  \\\n",
      "0  1000092795.jpg              0   \n",
      "1  1000092795.jpg              1   \n",
      "2  1000092795.jpg              2   \n",
      "3  1000092795.jpg              3   \n",
      "4  1000092795.jpg              4   \n",
      "\n",
      "                                             comment  \n",
      "0  Two young guys with shaggy hair look at their ...  \n",
      "1  Two young , White males are outside near many ...  \n",
      "2   Two men in green shirts are standing in a yard .  \n",
      "3       A man in a blue shirt standing in a garden .  \n",
      "4            Two friends enjoy time spent together .  \n",
      "Saving cleaned data to: C:\\Users\\nputta\\Downloads\\OMVK_MS_PROJECT\\cleaned_data.csv\n",
      "Cleaned data saved to C:\\Users\\nputta\\Downloads\\OMVK_MS_PROJECT\\cleaned_data.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def clean_and_reorganize_data(file_path, output_file):\n",
    "    \"\"\"\n",
    "    Clean and reorganize data into a tabular format with columns:\n",
    "    'image_name', 'comment_number', 'comment'.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the input CSV file.\n",
    "        output_file (str): Path to save the cleaned CSV file.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load the raw file into memory\n",
    "        print(f\"Reading the file: {file_path}\")\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            lines = f.readlines()\n",
    "\n",
    "        # Debug: Check if lines are read\n",
    "        if not lines:\n",
    "            print(\"Error: Input file is empty or unreadable.\")\n",
    "            return\n",
    "        \n",
    "        # Clean up lines by stripping extra spaces and quotation marks\n",
    "        cleaned_lines = []\n",
    "        for line in lines:\n",
    "            cleaned_line = line.replace('\"', '').strip()  # Remove quotation marks\n",
    "            cleaned_lines.append(cleaned_line)\n",
    "\n",
    "        # Debug: Print first few cleaned lines\n",
    "        print(\"Cleaned Lines (First 5):\")\n",
    "        print(cleaned_lines[:5])\n",
    "\n",
    "        # Save the cleaned content temporarily\n",
    "        temp_file = \"temp_cleaned_file.csv\"\n",
    "        with open(temp_file, 'w', encoding='utf-8') as f:\n",
    "            f.write(\"\\n\".join(cleaned_lines))\n",
    "\n",
    "        # Read the cleaned file with a proper delimiter\n",
    "        print(f\"Reading temporary cleaned file: {temp_file}\")\n",
    "        data = pd.read_csv(temp_file, delimiter='|', engine='python', skipinitialspace=True)\n",
    "\n",
    "        # Debug: Check if data is loaded\n",
    "        if data.empty:\n",
    "            print(\"Error: No data loaded from the temporary file.\")\n",
    "            return\n",
    "        \n",
    "        # Rename columns and strip whitespace\n",
    "        data.columns = ['image_name', 'comment_number', 'comment']\n",
    "        data['image_name'] = data['image_name'].str.strip()\n",
    "        data['comment_number'] = data['comment_number'].str.strip()\n",
    "        data['comment'] = data['comment'].str.strip()\n",
    "\n",
    "        # Debug: Print cleaned data for validation\n",
    "        print(\"Cleaned Data (First 5 Rows):\")\n",
    "        print(data.head())\n",
    "\n",
    "        # Save the cleaned data to a new CSV file\n",
    "        print(f\"Saving cleaned data to: {output_file}\")\n",
    "        data.to_csv(output_file, index=False)\n",
    "        print(f\"Cleaned data saved to {output_file}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error cleaning and reorganizing data: {e}\")\n",
    "\n",
    "# Example usage\n",
    "file_path = r\"C:\\Users\\nputta\\Downloads\\OMVK_MS_PROJECT\\results.csv\"  # Path to the raw CSV file\n",
    "output_file = r\"C:\\Users\\nputta\\Downloads\\OMVK_MS_PROJECT\\cleaned_data.csv\"  # Path to save the cleaned CSV file\n",
    "\n",
    "clean_and_reorganize_data(file_path, output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading CSV file: C:\\Users\\nputta\\Downloads\\OMVK_MS_PROJECT\\cleaned_data.csv\n",
      "Generated Image-Caption Mapping (Preview):\n",
      "{\n",
      "    \"1000092795.jpg\": [\n",
      "        \"Two young guys with shaggy hair look at their hands while hanging out in the yard .\",\n",
      "        \"Two young , White males are outside near many bushes .\",\n",
      "        \"Two men in green shirts are standing in a yard .\",\n",
      "        \"A man in a blue shirt standing in a garden .\",\n",
      "        \"Two friends enjoy time spent together .\"\n",
      "    ],\n",
      "    \"10002456.jpg\": [\n",
      "        \"Several men in hard hats are operating a giant pulley system .\",\n",
      "        \"Workers look down from up above on \n",
      "Saving JSON file to: C:\\Users\\nputta\\OneDrive - California State University, Sacramento\\De\n",
      "JSON file saved successfully to C:\\Users\\nputta\\OneDrive - California State University, Sacramento\\De\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "\n",
    "def create_image_caption_json(csv_file_path, image_folder, output_json_file):\n",
    "    \"\"\"\n",
    "    Create a JSON file mapping image filenames to their associated captions.\n",
    "\n",
    "    Args:\n",
    "        csv_file_path (str): Path to the cleaned CSV file.\n",
    "        image_folder (str): Path to the folder containing image files.\n",
    "        output_json_file (str): Path to save the resulting JSON file.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load the CSV file into a DataFrame\n",
    "        print(f\"Loading CSV file: {csv_file_path}\")\n",
    "        data = pd.read_csv(csv_file_path)\n",
    "\n",
    "        # Validate the required columns\n",
    "        required_columns = ['image_name', 'comment_number', 'comment']\n",
    "        for column in required_columns:\n",
    "            if column not in data.columns:\n",
    "                print(f\"Error: Column '{column}' not found in CSV file.\")\n",
    "                return\n",
    "\n",
    "        # Group captions by image_name\n",
    "        grouped_data = data.groupby('image_name')['comment'].apply(list).to_dict()\n",
    "\n",
    "        # Match image names with actual files in the image folder\n",
    "        image_caption_mapping = {}\n",
    "        for image_name, captions in grouped_data.items():\n",
    "            image_path = os.path.join(image_folder, image_name)\n",
    "            if os.path.exists(image_path):\n",
    "                image_caption_mapping[image_name] = captions\n",
    "            else:\n",
    "                print(f\"Warning: Image '{image_name}' not found in {image_folder}\")\n",
    "\n",
    "        # Debug: Print the generated mapping\n",
    "        print(\"Generated Image-Caption Mapping (Preview):\")\n",
    "        print(json.dumps(image_caption_mapping, indent=4)[:500])  # Print first 500 characters\n",
    "\n",
    "        # Save the result as a JSON file\n",
    "        print(f\"Saving JSON file to: {output_json_file}\")\n",
    "        with open(output_json_file, 'w') as json_file:\n",
    "            json.dump(image_caption_mapping, json_file, indent=4)\n",
    "\n",
    "        print(f\"JSON file saved successfully to {output_json_file}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating image-caption JSON: {e}\")\n",
    "\n",
    "# Example usage\n",
    "csv_file_path = r\"C:\\Users\\nputta\\Downloads\\OMVK_MS_PROJECT\\cleaned_data.csv\"  # Path to the cleaned CSV file\n",
    "image_folder = r\"C:\\Users\\nputta\\Downloads\\OMVK_MS_PROJECT\\flickr30k_images\"  # Path to the folder containing images\n",
    "output_json_file = r\"C:\\Users\\nputta\\OneDrive - California State University, Sacramento\\De\"  # Path to save JSON file\n",
    "\n",
    "create_image_caption_json(csv_file_path, image_folder, output_json_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nputta\\OneDrive - California State University, Sacramento\\De\n"
     ]
    }
   ],
   "source": [
    "print(output_json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Images: 31783, Total Captions: 31783\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# Load JSON file\n",
    "json_file_path = r\"C:\\Users\\nputta\\Downloads\\OMVK_MS_PROJECT\\Project_outputs.json.temp\"\n",
    "image_folder = r\"C:\\Users\\nputta\\Downloads\\OMVK_MS_PROJECT\\flickr30k_images\" \n",
    "\n",
    "with open(json_file_path, 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Map images to captions\n",
    "image_paths = [os.path.join(image_folder, img) for img in data.keys()]\n",
    "captions = list(data.values())\n",
    "print(f\"Total Images: {len(image_paths)}, Total Captions: {len(captions)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split into training and validation\n",
    "train_image_paths, val_image_paths, train_captions, val_captions = train_test_split(\n",
    "    image_paths, captions, test_size=0.2, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
